{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"CVRO-mi0IdoZ"},"source":["This notebook is adapted from the official PyTorch tutorial on [tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nZTmFNY5JEXU"},"source":["[PyTorch](https://pytorch.org/) is a popular deep-learning framework that allows you to \n","\n","*   build a neural network of arbitrary complexity; \n","*   perform computations on **hardware accelerators** (GPUs, TPUs, ...); and\n","*   automatically compute the gradient of the loss function w.r.t the weight vectors in your neural network\n","\n","among many others. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-HzMtagMMPb2"},"source":["[Tensors](https://pytorch.org/docs/stable/tensors.html) are at the core of PyTorch, as they are the only way data is being represented in PyTorch. \n","\n","Whether you have texts, images, videos or even molecules as your input data, you will have to convert them into tensors somehow before unleashing the power of PyTorch!"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JFRdlxs7HmPs"},"source":["# Tensors\n","\n","Tensors are a specialized data structure that are very similar to arrays and matrices.\n","In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n","\n","Tensors are similar to [NumPy’s](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other **hardware accelerators**. In fact, tensors and\n","NumPy arrays can often share the same underlying memory, eliminating the need to copy data. Tensors\n","are also optimized for **automatic differentiation**. \n","\n","If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. ~If not, follow along!~ (No, at this point in MADS, you must have been familiar with NumPy already!)\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LvErjnkxHmPu"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9JMxAxplHmPv"},"source":["## Initializing a Tensor\n","\n","Tensors can be initialized in various ways. A more complete list of tensor-creation operations can be found [here](https://pytorch.org/docs/stable/torch.html#creation-ops). \n","\n","Take a look at the following examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is automatically inferred.\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jnELDDlOHmPv"},"outputs":[],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180,"status":"ok","timestamp":1669908323386,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"RXycJ7ZkSspI","outputId":"a3489b6a-ca3f-4d98-fbc5-bf72d513c45a"},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["x_data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8YD1EaZAHmPv"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa).\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kDzO6xbsHmPw"},"outputs":[],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669908368931,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"NDRkwb18S3Qn","outputId":"a926a244-eb7c-4e27-d311-53b1c645532e"},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["x_np"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8BCaQUveHmPw"},"source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, data type) of the argument tensor, unless explicitly overridden.\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1669908544341,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"hu-3XRMwHmPw","outputId":"bad30940-51c6-4629-f454-473a2f89de03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Fives Tensor: \n"," tensor([[5, 5],\n","        [5, 5]]) \n","\n","Random Tensor: \n"," tensor([[0.6894, 0.3835],\n","        [0.5815, 0.4248]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_fives = torch.full_like(x_data, 5)\n","print(f\"Fives Tensor: \\n {x_fives} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HykpYXNkHmPx"},"source":["**With random or constant values:**\n","\n","``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n","\n","More random tensor creation operations are listed under the [Random sampling](https://pytorch.org/docs/stable/torch.html#random-sampling) section. Another commonly used one is `torch.randn` that draws numbers from the standard normal distribution. \n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1669908807735,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"s6UIQ75bHmPx","outputId":"d947620b-1c1c-4568-dff3-dd9fb6bd7651"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Tensor: \n"," tensor([[0.7055, 0.9311, 0.3119],\n","        [0.3061, 0.6225, 0.2105]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","Fives Tensor: \n"," tensor([[5., 5., 5.],\n","        [5., 5., 5.]])\n"]}],"source":["shape = (2, 3)\n","rand_tensor = torch.rand(shape) # uniform random numbers from [0, 1]\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","fives_tensor = torch.full(shape, fill_value=5.0)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n","print(f\"Fives Tensor: \\n {fives_tensor}\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Tensor: \n"," tensor([[[0.8984],\n","         [0.2866],\n","         [0.5204]],\n","\n","        [[0.4417],\n","         [0.3098],\n","         [0.6323]]]) \n","\n","Ones Tensor: \n"," tensor([[[1.],\n","         [1.],\n","         [1.]],\n","\n","        [[1.],\n","         [1.],\n","         [1.]]]) \n","\n","Zeros Tensor: \n"," tensor([[[0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.]]])\n","Fives Tensor: \n"," tensor([[[5.],\n","         [5.],\n","         [5.]],\n","\n","        [[5.],\n","         [5.],\n","         [5.]]])\n"]}],"source":["shape = (2, 3, 1)\n","rand_tensor = torch.rand(shape) # uniform random numbers from [0, 1]\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","fives_tensor = torch.full(shape, fill_value=5.0)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n","print(f\"Fives Tensor: \\n {fives_tensor}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8ZqYrQ1hHmPy"},"source":["--------------\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"r0cdC2WcHmPy"},"source":["## Attributes of a Tensor\n","\n","Tensor attributes describe their shape, data type, and the device on which they are stored.\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101,"status":"ok","timestamp":1669908958879,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"p7RXvIv1HmPy","outputId":"740415a9-51ed-4689-bd1b-4d5480b8902f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3, 4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LSVoSLbIWghj"},"source":["A tensor also has a **method** called `size` to return its `shape`. "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1669909040011,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"FBlg3YYvWWxr","outputId":"c2bd9a65-c255-46b3-8940-1bb346a046fe"},"outputs":[{"data":{"text/plain":["torch.Size([3, 4])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tensor.size()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QPTuziAiW7Fb"},"source":["Because `size` is a **method**, you can actually pass in an argument specifying a single dimension that you want to know the size of. "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103,"status":"ok","timestamp":1669909156682,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"7ZCa4d3fX8UK","outputId":"c4374c01-3216-4798-87c0-f33cff28426f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of dim 0: 3\n","Size of dim 1: 4\n"]}],"source":["print(f\"Size of dim 0: {tensor.size(dim=0)}\") # \"dim\" is what's known as \"axis\" in NumPy\n","print(f\"Size of dim 1: {tensor.size(dim=1)}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4DkiiRVzYMMf"},"source":["See its [documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html#torch-tensor-size) for a more complete description. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dKb0hlWigfM9"},"source":["Of course, you could also just slice the `shape` attribute:"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1669909192637,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"fubRbNk9gq2Z","outputId":"1ec32755-1d2b-4c6d-b80e-7097d79e10f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of dim 0: 3\n","Size of dim 1: 4\n"]}],"source":["print(f\"Size of dim 0: {tensor.shape[0]}\")\n","print(f\"Size of dim 1: {tensor.shape[1]}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IvAeviE0HmPz"},"source":["## Operations on Tensors\n","\n","Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n","indexing, slicing), sampling and more are\n","comprehensively described [here](https://pytorch.org/docs/stable/torch.html).\n","\n","Each of these operations can be run on the GPU (at typically higher speeds than on a\n","CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"KmkvuVYghX7R"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ner72b6jqF7F"},"source":["**Using GPUs**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"u9mJZ4g-hhU3"},"source":["How can we know if a GPU is available on our machine or not? "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1669909456523,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"PUa5lKiNhdwU","outputId":"6aa6a09e-6b3b-491e-a3b6-a7ecee603655"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n"]}],"source":["import math\n","# this ensures that the current MacOS version is at least 12.3+\n","print(torch.backends.mps.is_available())\n","# this ensures that the current current PyTorch installation was built with MPS activated.\n","print(torch.backends.mps.is_built())"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["99 5190.0439453125\n","199 3444.4609375\n","299 2287.40185546875\n","399 1520.3184814453125\n","499 1011.6849365234375\n","599 674.3607177734375\n","699 450.60430908203125\n","799 302.1492004394531\n","899 203.63247680664062\n","999 138.2399444580078\n","1099 94.82329559326172\n","1199 65.9898452758789\n","1299 46.83553695678711\n","1399 34.107521057128906\n","1499 25.647045135498047\n","1599 20.02140998840332\n","1699 16.279420852661133\n","1799 13.789353370666504\n","1899 12.131765365600586\n","1999 11.027870178222656\n","Result: y = -0.017983488738536835 + 0.8141233921051025 x + 0.0031024515628814697 x^2 + -0.08726843446493149 x^3\n"]}],"source":["dtype = torch.float\n","device = torch.device(\"mps\")\n","\n","# Create random input and output data\n","x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n","y = torch.sin(x)\n","\n","# Randomly initialize weights\n","a = torch.randn((), device=device, dtype=dtype)\n","b = torch.randn((), device=device, dtype=dtype)\n","c = torch.randn((), device=device, dtype=dtype)\n","d = torch.randn((), device=device, dtype=dtype)\n","\n","learning_rate = 1e-6\n","for t in range(2000):\n","    # Forward pass: compute predicted y\n","    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n","\n","    # Compute and print loss\n","    loss = (y_pred - y).pow(2).sum().item()\n","    if t % 100 == 99:\n","        print(t, loss)\n","\n","# Backprop to compute gradients of a, b, c, d with respect to loss\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_a = grad_y_pred.sum()\n","    grad_b = (grad_y_pred * x).sum()\n","    grad_c = (grad_y_pred * x ** 2).sum()\n","    grad_d = (grad_y_pred * x ** 3).sum()\n","\n","    # Update weights using gradient descent\n","    a -= learning_rate * grad_a\n","    b -= learning_rate * grad_b\n","    c -= learning_rate * grad_c\n","    d -= learning_rate * grad_d\n","\n","\n","print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='mps')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9h-BgrQUht0B"},"source":["\"GPU\"s are often referred to as \"cuda\" in PyTorch. [CUDA](https://developer.nvidia.com/cuda-toolkit) is a software toolkit that supports programming on Nvidia's GPUs. Luckily, we don't have to program in CUDA ourselves thanks to PyTorch. But the forerunners of deep learning must have written CUDA code themselves in C++ if they were to use GPUs!\n","\n","[Here](https://developer.nvidia.com/cuda-gpus) is a cool page for checking how powerful your GPU is in terms of its compute capability. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kOPsusEck_M3"},"source":["The `nvidia-smi` terminal command is useful for checking the status of your GPU. \n","\n","See more on the [NVIDIA System Management Interface](https://developer.nvidia.com/nvidia-system-management-interface) page. "]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1669909594479,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"QkjkNn9LlBTa","outputId":"31c99326-1f93-49b6-8423-2c1bdfd9a2b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: nvidia-smi\n"]}],"source":["! nvidia-smi"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JqLS9rsMl5D5"},"source":["To switch seamleassly from CPU to GPU or vice versa, you can define a `device` object that represents your current choice of device to run tensor operations on. This allows you to write [device-agnostic](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code) code. "]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1669909801952,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"61ucODVyHmPz","outputId":"d2afbbef-03b0-43a3-ef04-440ae1038f15"},"outputs":[{"data":{"text/plain":["device(type='mps')"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n","device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6hpE6WUlmzZ9"},"source":["Now, for any tensor creation operations that accept a keyword argument `device`, you can pass this `device` in and your new tensor will be right on that device. For example,  "]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4604,"status":"ok","timestamp":1669909885204,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"NqGKxFRWmyOD","outputId":"1b11416c-a5b6-4e91-e8e6-24135b1f6946"},"outputs":[{"data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], device='mps:0')"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["ones_tensor = torch.ones((2, 3), device=device)\n","ones_tensor"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":766,"status":"ok","timestamp":1669909914268,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"sxVsjFVHn2Mq","outputId":"31b5cb77-d58c-4c8b-c4b3-0f43a514015c"},"outputs":[{"data":{"text/plain":["device(type='mps', index=0)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["ones_tensor.device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A8BkQbbnoDve"},"source":["If one tensor is already on a specific device, you can create a new tensor on the same device using `.*_like` methods. In this case, you don't need to pass in `device`. For example, "]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1669909992820,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"b_37-3ZZoVg4","outputId":"ebdf6be5-9452-45ad-a6c4-b4cdbcac8175"},"outputs":[{"data":{"text/plain":["device(type='mps', index=0)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["fives_tensor = torch.full_like(ones_tensor, 5.0)\n","fives_tensor.device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wUlgRM5ApD3W"},"source":["You may often find yourself in a situation where you first create a tensor on CPU but later on want to move it to GPU. In that case, you can use the `.to` method of a tensor:"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1669910056910,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"UQfuA3LUo-Go","outputId":"3570627e-658f-4b6f-8454-94fa93128685"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)\n","x_data.device"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1669910085458,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"OF1sGVhOpgC-","outputId":"f04010de-70e1-48f4-eb68-a66ad4705ce6"},"outputs":[{"data":{"text/plain":["device(type='mps', index=0)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["x_data = x_data.to(device)\n","x_data.device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9J3HMxlWHmPz"},"source":["But keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZJVJhVSwHmP0"},"source":["**Standard numpy-like indexing and slicing:**\n","\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113,"status":"ok","timestamp":1669910237784,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"DuG3w2ixHmP0","outputId":"fa760d76-1e1f-4e39-b510-c9465ef2b3cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["First row: tensor([1., 1., 1., 1.])\n","First column: tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print(f\"First row: {tensor[0]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Last column: {tensor[..., -1]}\")\n","tensor[:,1] = 0\n","print(tensor)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bW1QfytS9xyv"},"source":["**Joining tensors**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qAsjgdSaHmP0"},"source":["You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1669910302587,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"GjEBYdEiHmP0","outputId":"2df35e2f-478d-4368-9dc5-9acaec74d57e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1) # same as np.hstack\n","print(t1)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1669910361118,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"VWuQ02TmsRYx","outputId":"589b1049-3307-4388-87ec-22a36f814c66"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["t2 = torch.cat([tensor, tensor, tensor], dim=0) # same as np.vstack\n","print(t2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MF2Iw0jospc7"},"source":["See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n","another tensor joining op that is subtly different from ``torch.cat``. It always creates a new dimension. "]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1669910404535,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"evEDsdQIsa0w","outputId":"1dd91e33-27cb-4732-ed97-76dfd78009dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.]],\n","\n","        [[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.]],\n","\n","        [[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.]]])\n"]}],"source":["t3 = torch.stack([tensor, tensor, tensor], dim=0) # same as np.stack\n","print(t3)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BFdEsxeKth-Y"},"source":["The difference lies in the shape of the new tensor:"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1669910452565,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"rrHqPgBXtRGb","outputId":"1c59013e-3ec2-404b-a46d-9a21b8beaba4"},"outputs":[{"name":"stdout","output_type":"stream","text":["The size of t2: torch.Size([12, 4])\n","The size of t3: torch.Size([3, 4, 4])\n"]}],"source":["print(f\"The size of t2: {t2.size()}\") # torch.cat([tensor, tensor, tensor], dim=0)\n","print(f\"The size of t3: {t3.size()}\") # torch.stack([tensor, tensor, tensor], dim=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TTbM5nRaHmP0"},"source":["**Arithmetic operations**\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1669910664729,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"vB4NEIp2HmP0","outputId":"9b99e89b-02bf-4577-d049-e59f859660ce"},"outputs":[{"data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3) # or just y3 = torch.matmul(tensor, tensor.T)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"clZnbGakHmP1"},"source":["**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n","values of a tensor into one value, you can convert it to a Python\n","numerical value using ``item()``:\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1669910729466,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"GsJ_N7bZHmP1","outputId":"ee260651-b95d-4fbc-b687-bb9c5bcd15d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4V_vxDNoHmP1"},"source":["**In-place operations**\n","Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n","For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``. More can be found [here](https://pytorch.org/docs/stable/tensors.html#tensor-class-reference). \n","\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1669910884627,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"cQe3b5opHmP1","outputId":"493d4060-e7d9-49ad-f4f2-5c5f8d63cb42"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TZ6Fcne8HmP1"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n","     of history. <b>Hence, their use is discouraged.</b></p></div>\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TskRH0OYvaLj"},"source":["Typically, a tensor operation can be invoked in three ways, especially for the arithmetic operations. \n","\n","Take the `sqrt` operation as an example:"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1669911081162,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"okgFahGAv8LU","outputId":"9444c5b4-707e-4c5e-c6f6-cf39c3f959a5"},"outputs":[{"data":{"text/plain":["tensor([[0.6532, 0.7038, 0.1374],\n","        [0.2304, 0.7132, 0.8579]])"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["rand_tensor = torch.rand(2, 3)\n","\n","sqrt_first = torch.sqrt(rand_tensor) # torch.[op](tensor, ...)\n","sqrt_second = rand_tensor.sqrt()     # tensor.[op](...)\n","rand_tensor.sqrt_()                  # tensor.[op]_(...) (in-place)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1669911115125,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"O3G-buofw18L","outputId":"38a8a762-0a52-4b04-adea-a8f7d688e3b7"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["torch.allclose(sqrt_first, sqrt_second)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111,"status":"ok","timestamp":1669911129403,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"bsARHTqnw-JO","outputId":"ed670ba0-9a60-4b87-8572-70aaca6d9e86"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["torch.allclose(sqrt_first, rand_tensor)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZAdqq7o-HmP1"},"source":["--------------\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KtmoHI3sHmP2"},"source":["\n","## Bridge with NumPy\n","Tensors on the CPU and NumPy arrays can share their underlying memory\n","locations, and changing one will change\tthe other.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jPyplvF_HmP2"},"source":["### Tensor to NumPy array\n","\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1669911246539,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"jwMUjilkHmP2","outputId":"6308863e-3edc-475a-f0db-b69af8112406"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IV2Smn1VHmP2"},"source":["A change in the tensor reflects in the NumPy array.\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":744,"status":"ok","timestamp":1669911274718,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"Om7oE7trHmP2","outputId":"41541dca-1702-4a09-a9a0-1de4d0e3a787"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"L23O9MVBHmP2"},"source":["### NumPy array to Tensor\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"gCyQ7Ob7HmP3"},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZvaJZ_HBHmP3"},"source":["Changes in the NumPy array reflects in the tensor.\n","\n"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126,"status":"ok","timestamp":1669911323568,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"tgxvABJHHmP3","outputId":"bf18bf0a-9390-4c42-e7b1-faaa566f1e53"},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t6K9e2a84SzX"},"source":["Tensors on GPUs (or other non-CPU devices) cannot be cast into NumPy arrays directly. They need to be first copied to CPU."]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"elapsed":164,"status":"error","timestamp":1669911386077,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"XASfT3qp4iUN","outputId":"f9176eef-8cb2-4731-ee65-3269fe122352"},"outputs":[{"ename":"TypeError","evalue":"can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/jacob/Documents/GitHub/Colab/MADS/642_Deep Learning/resources/PyTorch Tutorial/1. tensors.ipynb Cell 81\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacob/Documents/GitHub/Colab/MADS/642_Deep%20Learning/resources/PyTorch%20Tutorial/1.%20tensors.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacob/Documents/GitHub/Colab/MADS/642_Deep%20Learning/resources/PyTorch%20Tutorial/1.%20tensors.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x\u001b[39m.\u001b[39;49mnumpy()\n","\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}],"source":["x = torch.ones((2, 3), device=\"mps\")\n","x.numpy()"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1669911413517,"user":{"displayName":"Yumou Wei","userId":"07928071509313005295"},"user_tz":300},"id":"eNcy-mEB5APK","outputId":"1e11e81e-13af-46f1-f028-25b50d1d8abf"},"outputs":[{"data":{"text/plain":["array([[1., 1., 1.],\n","       [1., 1., 1.]], dtype=float32)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["x.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kuag3jZa5HLM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}
